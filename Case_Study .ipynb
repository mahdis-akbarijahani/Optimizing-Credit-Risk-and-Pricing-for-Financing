{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36qok7b_8yxX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n",
        "from google.colab import files\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()\n",
        "filename = next(iter(uploaded))\n",
        "df = pd.read_excel(filename, sheet_name=\"Loan Data\")"
      ],
      "metadata": {
        "id": "o_F86iNeBXNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Dataset Info:\")\n",
        "df.info()"
      ],
      "metadata": {
        "id": "-m6a3N5VRaKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nFirst 5 Rows:\")\n",
        "df.head(10)"
      ],
      "metadata": {
        "id": "sAr5qKAKSDtW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nMissing Values:\")\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "xeJnajbwSG9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean the Data (Scope 1)\n",
        "# Handle missing values\n",
        "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns"
      ],
      "metadata": {
        "id": "-LjibqKTSLy9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Impute numeric with median\n",
        "for col in numeric_cols:\n",
        "    df[col].fillna(df[col].median(), inplace=True)"
      ],
      "metadata": {
        "id": "-Lwi6R4TSVrx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Impute categorical with mode\n",
        "for col in categorical_cols:\n",
        "    df[col].fillna(df[col].mode()[0], inplace=True)"
      ],
      "metadata": {
        "id": "CeSoO5UmSfiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle outliers (cap at 1.5*IQR)\n",
        "# Columns you’re checking\n",
        "cols = ['loan_amount', 'annual_income', 'property_value']\n",
        "\n",
        "# One subplot per column\n",
        "fig, axes = plt.subplots(1, len(cols), figsize=(5 * len(cols), 4), sharey=False)\n",
        "\n",
        "for ax, col in zip(axes, cols):\n",
        "\n",
        "    Q1, Q3 = df[col].quantile([0.25, 0.75])\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "\n",
        "    mask_out = (df[col] < lower_bound) | (df[col] > upper_bound)\n",
        "    mask_in  = ~mask_out\n",
        "\n",
        "    ax.scatter(df.index[mask_in],  df.loc[mask_in,  col], s=12, label='In‑range')\n",
        "    ax.scatter(df.index[mask_out], df.loc[mask_out, col], s=12, color='red', label='Outlier')\n",
        "    ax.set_title(col.replace('_', ' ').title())\n",
        "    ax.set_xlabel('Row index')\n",
        "    ax.set_ylabel(col)\n",
        "    ax.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "lB9v8wZEpHTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nAfter Cleaning - Missing Values:\")\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "XO1jvgp-Sl1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\\033[1mSummary Statistics (Numerical):\\033[0m\")\n",
        "print(df[['loan_amount', 'loan_term_months', 'schufa_score', 'annual_income']].describe())\n",
        "print(\"\\n\\033[1mSummary Statistics (Categorical):\\033[0m\")\n",
        "print(df['property_ownership'].value_counts())\n",
        "print(df['state'].value_counts())"
      ],
      "metadata": {
        "id": "hIiQdxmmU7WE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Payment history summary\n",
        "payment_data = pd.read_excel(filename, sheet_name=\"Payment History\")\n",
        "print(\"\\n\\033[1mPayment History Summary:\\033[0m\")\n",
        "print(payment_data[['amount_due', 'amount_paid', 'days_late']].describe())"
      ],
      "metadata": {
        "id": "bYNCbXWoVGYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#distribution of credit scores\n",
        "plt.figure(figsize=(6,3))\n",
        "sns.histplot(df[\"schufa_score\"], kde=True)\n",
        "plt.title(\"SCHUFA Score Distribution\")\n",
        "plt.xlabel(\"Score\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Z_3HJItT7amI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Risk Categories (Scope 2)\n",
        "# Define risk based on Schufa score, debt-to-income, and previous defaults\n",
        "df['risk_category'] = pd.qcut(df['schufa_score'], q=3, labels=['High', 'Medium', 'Low'])\n",
        "df.loc[(df['debt_to_income'] > df['debt_to_income'].quantile(0.75)) |\n",
        "       (df['previous_defaults'] > 0), 'risk_category'] = 'High'\n",
        "df.loc[(df['debt_to_income'] < df['debt_to_income'].quantile(0.25)) &\n",
        "       (df['previous_defaults'] == 0), 'risk_category'] = 'Low'\n",
        "print(\"\\nRisk Category Distribution:\")\n",
        "print(df['risk_category'].value_counts())"
      ],
      "metadata": {
        "id": "D2Zbfz_1Xq0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#distribution of applicants across risk buckets\n",
        "# Simple count plot (bars show how many rows fall into each bucket)\n",
        "plt.figure(figsize=(6, 3))\n",
        "sns.countplot(\n",
        "    data=df,\n",
        "    x=\"risk_category\",\n",
        "    order=[\"Low\", \"Medium\", \"High\"],\n",
        "    width=0.5\n",
        ")"
      ],
      "metadata": {
        "id": "wu26dK-LGnkZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ── Histogram: Schufa Score Distribution\n",
        "plt.subplot(1, 2, 1)\n",
        "\n",
        "for category in ['Low', 'Medium', 'High']:\n",
        "    sns.histplot(\n",
        "        df.loc[df['risk_category'] == category, 'schufa_score'],\n",
        "        label=category,\n",
        "        kde=True,\n",
        "        alpha=0.7                    # slight transparency, keeps default colours\n",
        "    )\n",
        "\n",
        "plt.title('Schufa Score Distribution – Risk Profile', fontsize=12, pad=12)\n",
        "plt.xlabel('Schufa Score', labelpad=8)\n",
        "\n",
        "# Legend outside the axes, upper‑right\n",
        "plt.legend(\n",
        "    title='Risk Category',          # professional heading\n",
        "    loc='upper left',\n",
        "    bbox_to_anchor=(1.02, 1),       # x > 1 moves it outside\n",
        "    frameon=True\n",
        ")\n",
        "\n",
        "plt.tight_layout()                  # adjust layout for the external legend\n"
      ],
      "metadata": {
        "id": "3YnjNiJIaDhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "ax = sns.scatterplot(\n",
        "        x='loan_amount',\n",
        "        y='debt_to_income',\n",
        "        hue='risk_category',\n",
        "        size='default_flag',\n",
        "        data=df,\n",
        "        alpha=0.85                     # keep points slightly transparent\n",
        ")\n",
        "\n",
        "# Axis titles\n",
        "ax.set_title('Loan Amount vs. Debt‑to‑Income – Risk Profile', fontsize=12, pad=12)\n",
        "ax.set_xlabel('Loan Amount', labelpad=8)\n",
        "ax.set_ylabel('Debt‑to‑Income Ratio', labelpad=8)\n",
        "\n",
        "# Move the combined legend *outside* the plot, upper‑right\n",
        "handles, labels = ax.get_legend_handles_labels()\n",
        "ax.legend(handles, labels,\n",
        "          title='Risk Category',                 # professional legend heading\n",
        "          loc='upper left',\n",
        "          bbox_to_anchor=(1.02, 1),              # x > 1 ⇒ legend outside\n",
        "          frameon=True)\n",
        "\n",
        "plt.tight_layout()  # ensure the figure accommodates the external legend\n",
        "\n"
      ],
      "metadata": {
        "id": "7DJmLrsUaSpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,6))\n",
        "corr = df[features + ['default_flag']].corr()\n",
        "sns.heatmap(corr, annot=True, cmap='coolwarm', center=0)\n",
        "plt.title(\"Feature vs. Target Correlation (Raw Units)\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "r9YKGiD8DHx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare Data for Modeling (Scope 3)\n",
        "features = ['schufa_score', 'loan_amount', 'income_to_loan_ratio', 'debt_to_income',\n",
        "            'previous_defaults', 'late_payments_30', 'late_payments_90']\n",
        "categorical_cols = ['property_ownership', 'state']\n",
        "\n"
      ],
      "metadata": {
        "id": "9RBkVpZKaXEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode categorical variables\n",
        "df_encoded = pd.get_dummies(df[features + categorical_cols], columns=categorical_cols)\n",
        "\n",
        "X = df_encoded               # predictors\n",
        "y = df['default_flag']       # binary target: 1 = default, 0 = no default"
      ],
      "metadata": {
        "id": "FkUjV-eucQVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "vLj759Zock-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "CIW7FEibcrJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build and Train Logistic Regression Model (Scope 3)\n",
        "model = LogisticRegression(random_state=42, max_iter=1000)\n",
        "model.fit(X_train_scaled, y_train)"
      ],
      "metadata": {
        "id": "JKIbghPXcuvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate Model Performance (Scope 3)\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "auc = roc_auc_score(y_test, model.predict_proba(X_test_scaled)[:, 1])"
      ],
      "metadata": {
        "id": "WHXoL_jxdHyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nModel Performance:\")\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"ROC-AUC: {auc:.2f}\")"
      ],
      "metadata": {
        "id": "OgPAZd1cdL9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "proba = model.predict_proba(X_test_scaled)[:, 1]\n",
        "fpr, tpr, _ = roc_curve(y_test, proba)\n",
        "auc  = roc_auc_score(y_test, proba)\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.plot(fpr, tpr, linewidth=2, label=f\"AUC = {auc:0.3f}\")\n",
        "plt.plot([0,1], [0,1], \"k--\", linewidth=1)\n",
        "plt.xlabel(\"False Positive Rate\"); plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC – Logistic Model\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"roc_curve.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3448mzKNdlr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarize Insights (Scope 4)\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Coefficient': model.coef_[0]\n",
        "}).sort_values(by='Coefficient', ascending=False)"
      ],
      "metadata": {
        "id": "tOV1dmvydVS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nKey Insights:\")\n",
        "print(\"- Schufa score and debt-to-income ratio are strong predictors of default.\")\n",
        "print(f\"- Risk Category Distribution: {df['risk_category'].value_counts().to_dict()}\")\n",
        "print(\"\\nFeature Importance:\")\n",
        "print(feature_importance)"
      ],
      "metadata": {
        "id": "3McZTiHvdaBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code loads a saved loan risk prediction model and its related files. It takes information about a loan applicant (like credit score, loan amount, and other financial details), prepares this data correctly, and then uses the model to estimate how likely it is that the applicant will default on the loan (fail to pay it back).\n",
        "\n",
        "The code also creates a small web service (using Flask) that lets other programs send applicant data and get back a risk score in real-time. This way, the loan system can quickly decide if a person is a good or risky borrower."
      ],
      "metadata": {
        "id": "Afv9DZdDgAFJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "base_path = os.getcwd()  # current working directory\n",
        "\n",
        "with open(os.path.join(base_path, \"model.pkl\"), \"rb\") as f:\n",
        "    model = pickle.load(f)\n",
        "with open(os.path.join(base_path, \"scaler.pkl\"), \"rb\") as f:\n",
        "    scaler = pickle.load(f)\n",
        "with open(os.path.join(base_path, \"columns.pkl\"), \"rb\") as f:\n",
        "    columns = pickle.load(f)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "z2JYpPQvVYIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Saved model.pkl, scaler.pkl, columns.pkl\")"
      ],
      "metadata": {
        "id": "YUyyHkRrXEj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_single(sample: dict) -> dict:\n",
        "    \"\"\"Return probability & class for one applicant dict.\"\"\"\n",
        "    df_s = pd.DataFrame([sample])\n",
        "    df_enc = pd.get_dummies(df_s, columns=categorical_cols)\n",
        "    df_align = df_enc.reindex(columns=X.columns, fill_value=0)\n",
        "    df_align[numeric_features] = scaler.transform(df_align[numeric_features])\n",
        "    proba = model.predict_proba(df_align)[0,1]\n",
        "    return {\"probability\": round(float(proba),4), \"class\": int(proba>=0.5)}\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5BOzpzzJaZU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_applicant = {\n",
        "    \"schufa_score\": 700,\n",
        "    \"loan_amount\": 15000,\n",
        "    \"income_to_loan_ratio\": 2.3,\n",
        "    \"debt_to_income\": 0.35,\n",
        "    \"previous_defaults\": 0,\n",
        "    \"late_payments_30\": 1,\n",
        "    \"late_payments_90\": 0,\n",
        "    \"property_ownership\": \"mortgage\",\n",
        "    \"state\": \"BY\"\n",
        "}\n"
      ],
      "metadata": {
        "id": "9VUI8qrbahsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "for f in [\"model.pkl\",\"scaler.pkl\",\"columns.pkl\"]:\n",
        "    files.download(f)\n"
      ],
      "metadata": {
        "id": "-nMSCNoXanWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "from flask import Flask, request, jsonify\n",
        "import pickle, pandas as pd\n",
        "\n",
        "# --- Load artefacts ---------------------------------------------------------\n",
        "with open(\"model.pkl\", \"rb\") as f:   model   = pickle.load(f)\n",
        "with open(\"scaler.pkl\", \"rb\") as f:  scaler  = pickle.load(f)\n",
        "with open(\"columns.pkl\", \"rb\") as f: columns = pickle.load(f)\n",
        "\n",
        "numeric_features = [\n",
        "    \"schufa_score\",\"loan_amount\",\"income_to_loan_ratio\",\n",
        "    \"debt_to_income\",\"previous_defaults\",\n",
        "    \"late_payments_30\",\"late_payments_90\"\n",
        "]\n",
        "categorical_cols = [\"property_ownership\",\"state\"]\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route(\"/\")\n",
        "def home():\n",
        "    return \"Default‑probability Logistic Regression API is running!\"\n",
        "\n",
        "@app.route(\"/predict\", methods=[\"POST\"])\n",
        "def predict():\n",
        "    data = request.get_json()\n",
        "    df  = pd.DataFrame([data])\n",
        "    df  = pd.get_dummies(df, columns=categorical_cols)\n",
        "    df  = df.reindex(columns=columns, fill_value=0)\n",
        "    df[numeric_features] = scaler.transform(df[numeric_features])\n",
        "    proba = model.predict_proba(df)[0,1]\n",
        "    return jsonify({\"probability\": round(float(proba),4),\n",
        "                    \"class\": int(proba>=0.5)})\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run(debug=True)\n"
      ],
      "metadata": {
        "id": "T857MPAOcj79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('app.py')\n"
      ],
      "metadata": {
        "id": "dzz5aVfAcoGu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}